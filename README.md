Customized Dependency Parsing
===================



## Requirements
- python 2.7
- PyTorch v0.2

## Files
./model
- include training codes

./preprocess
- include mapping from json data to conll file 

./coco-caption
- evaluate coco caption with dependency sg parser

## Customized Dependency Scene Graph Parser
#### Data Split
For training (development) data, we adopt the overlap images between Visual Genome training (develpment) dataset and MSCOCO training (development) dataset.

#### Preprocessing ####
1. Split Visual Genome image_data, all_region_graphs, all_attributes into 10 pieces. (The size for the every first 9 pieces is all_region_graph.size()/10). The reason to split to 10 pieces is for acclerating the preprocessing speed. 
2. run
```
python split.py
python data_to_conll.py --input /media/Work_HD/yswang/dataset/visual_genome/preprocess/preprocess_json/pre_coco_train.json --output coco_train.conll --train True
```
--input:  processed data generated by split.py
--output: desired output
--train : determine whether the file is used for training or not




#### Training
```
cd ./model/
bash run.sh
```
In run.sh, you can set the paramters
```
time CUDA_VISIBLE_DEVICES=2 python src/parser.py --outdir ./output --train /media/Work_HD/yswang/dataset/glove/glove.6B/coco_train.conll --dev /media/Work_HD/yswang/dataset/glove/glove.6B/coco_dev.conll --epochs 30 --lstmdims 256 --lstmlayers 2  --k 3 --usehead --userl
```

#### Validation

```
cd ./model/src/utils/evaluation_script/
bash eval.sh
```
In eval.sh, pre_coco_dev.json is the ground truth file.

```
time python spice_eval.py /media/Work_HD/yswang/dataset/visual_genome/preprocess/preprocess_json/pre_coco_dev.json /media/Work_HD/yswang/bist-parser/barchybrid_v1_0/output/dev_coco_0001_8.conll
```
Remember to set nltk_wordnet path in `./model/src/utils/evaluation_script/spice_eval.py` to use wordnet for spice metric


## COCO Caption Evaluation
The details to evaluate COCO caption are in ./coco-caption.

## Image Retrieval 
1. First of all, run the following commands to get the ground truth
```
python retrieval_gt.py test.processed.json gt.pkl
python retrieval_gt.py dev.processed.json gt_dev.pkl
```
2. To calculate R@5, R@10, med score run,
```
python img_retrieval.py --input test.processed.json --mode 0 --pred dep.conll --gt gt.pkl
```
--mode: stand for 3 kinds of data format
0: conll file
1: Stanford parser format
2: Spice parser format

--pred: the predicted file from different parser
Dep parser test prediction: /media/Work_HD/yswang/imgrt/imgrt.conll
Dep parser dev prediction: /media/Work_HD/yswang/imgrt/imgrt_dev.conll

Stanford parser test prediction: /media/Work_HD/yswang/stanford-corenlp-full-2015-12-09/output_imgrt
Stanford parser dev prediction: /media/Work_HD/yswang/stanford-corenlp-full-2015-12-09/output_imgrt_dev

Spice parser test prediction: /media/Work_HD/yswang/imgrt/output_seb_test.json
Spice parser dev prediction:  /media/Work_HD/yswang/imgrt/output_seb_dev.json

--gt:
ground truth file genrated by retrieval_gt.py











